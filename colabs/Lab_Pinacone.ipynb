{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database"
      ],
      "metadata": {
        "id": "EHTLXkKOD3bj"
      },
      "id": "EHTLXkKOD3bj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Um Vector Database (ou banco de dados vetorial) √© um tipo de banco de dados especializado no armazenamento, indexa√ß√£o e busca eficiente de vetores de alta dimens√£o ‚Äî representa√ß√µes num√©ricas densas, geralmente extra√≠das de dados como textos, imagens, v√≠deos ou √°udio.\n",
        "\n",
        "Esses vetores s√£o a base de aplica√ß√µes de IA modernas, como:\n",
        "\n",
        "- Busca sem√¢ntica (semantic search)\n",
        "\n",
        "- Recupera√ß√£o aumentada por gera√ß√£o (RAG)\n",
        "\n",
        "- Recomenda√ß√£o de conte√∫do\n",
        "\n",
        "- Detec√ß√£o de similaridade\n",
        "\n",
        "## Por que vetores?\n",
        "Modelos de machine learning (como BERT, CLIP, OpenAI embeddings etc.) convertem entradas complexas (como textos) em vetores num√©ricos. Cada vetor representa o \"significado\" daquele dado em um espa√ßo matem√°tico. Com isso, √© poss√≠vel medir semelhan√ßa sem√¢ntica usando m√©tricas como:\n",
        "\n",
        "- Dist√¢ncia Euclidiana\n",
        "\n",
        "- Cosseno\n",
        "\n",
        "- Inner product\n",
        "\n",
        "## Pinecone ‚Äì O que √©?\n",
        "\n",
        "Pinecone √© uma Vector Database as a Service, gerenciada, escal√°vel e de alta performance. Ela permite que voc√™:\n",
        "\n",
        "- Armazene bilh√µes de vetores\n",
        "\n",
        "- Fa√ßa buscas vetoriais r√°pidas\n",
        "\n",
        "- Integre facilmente com LLMs (ex: OpenAI, Cohere)\n",
        "\n",
        "- Use com frameworks como LangChain, LlamaIndex, Haystack\n",
        "\n",
        "## Como funciona a arquitetura b√°sica?\n",
        "\n",
        "- Cria√ß√£o de vetores: Um modelo de IA transforma dados (como textos) em vetores.\n",
        "\n",
        "- Indexa√ß√£o: Esses vetores s√£o armazenados em Pinecone.\n",
        "\n",
        "- Consulta: Voc√™ envia um vetor de consulta, e Pinecone retorna os vetores mais semelhantes.\n",
        "\n",
        "- Integra√ß√£o com contexto: Em sistemas RAG, os resultados recuperados podem ser usados como contexto para LLMs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sTaqRFjNDswf"
      },
      "id": "sTaqRFjNDswf"
    },
    {
      "cell_type": "markdown",
      "id": "5ece3236",
      "metadata": {
        "id": "5ece3236"
      },
      "source": [
        "# üîç RAG com Pinecone + MongoDB + OpenAI\n",
        "\n",
        "Este notebook demonstra como construir um sistema de **Pergunta e Resposta com Busca Sem√¢ntica** (RAG - Retrieval-Augmented Generation), integrando:\n",
        "- Vetores sem√¢nticos com OpenAI\n",
        "- Armazenamento vetorial com Pinecone\n",
        "- Persist√™ncia dos documentos em MongoDB\n",
        "- Gera√ß√£o de resposta com contexto usando ChatGPT (GPT-3.5-turbo)\n",
        "\n",
        "Ideal para casos de uso como:\n",
        "- FAQ inteligentes\n",
        "- Chatbots com mem√≥ria contextual\n",
        "- Sistemas de suporte baseados em conhecimento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obter suas chaves de API do **Pinecone** e **OpenAI**, siga os passos abaixo:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Como obter a API Key do Pinecone**\n",
        "\n",
        "1. Acesse: [https://www.pinecone.io](https://www.pinecone.io)\n",
        "2. Clique em **‚ÄúStart for free‚Äù** e crie uma conta (ou fa√ßa login).\n",
        "3. No Dashboard:\n",
        "\n",
        "   * V√° para **API Keys** (menu lateral esquerdo).\n",
        "   * Copie a **API Key** (ex: `a1b2c3d4...`) e o **Environment** (ex: `gcp-starter`, `us-west1-gcp`).\n",
        "\n",
        "##--> Guarde essas informa√ß√µes, voc√™ usar√° assim:\n",
        "\n",
        "```python\n",
        "pinecone_api_key = \"SUA_PINECONE_API_KEY\"\n",
        "pinecone_env = \"us-west1-gcp\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Como obter a OpenAI API Key**\n",
        "\n",
        "1. Acesse: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n",
        "2. Fa√ßa login com sua conta da OpenAI.\n",
        "3. Clique em **‚ÄúCreate new secret key‚Äù**.\n",
        "4. Copie e salve a chave (voc√™ s√≥ ver√° uma vez!).\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "```python\n",
        "openai_api_key = \"sk-...\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üí° Dica de seguran√ßa:\n",
        "\n",
        "* Nunca compartilhe suas chaves publicamente.\n",
        "* Use vari√°veis de ambiente (como `os.getenv`) ou arquivos `.env` para maior seguran√ßa em produ√ß√£o.\n",
        "\n",
        "Se quiser, posso mostrar como armazenar essas chaves com seguran√ßa em um projeto Colab ou Python local. Deseja isso tamb√©m?\n"
      ],
      "metadata": {
        "id": "8sw32BTcEczT"
      },
      "id": "8sw32BTcEczT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48459f6",
      "metadata": {
        "id": "e48459f6"
      },
      "outputs": [],
      "source": [
        "# Instalar depend√™ncias\n",
        "!pip install openai pinecone-client pymongo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c807df7a",
      "metadata": {
        "id": "c807df7a"
      },
      "outputs": [],
      "source": [
        "# Configura√ß√µes (edite com suas chaves)\n",
        "openai_api_key = \"SUA_OPENAI_API_KEY\"\n",
        "pinecone_api_key = \"SUA_PINECONE_API_KEY\"\n",
        "pinecone_env = \"us-west1-gcp\"\n",
        "pinecone_index_name = \"rag-index\"\n",
        "\n",
        "mongodb_uri = \"mongodb://localhost:27017\"\n",
        "db_name = \"ragdb\"\n",
        "collection_name = \"faq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833ab690",
      "metadata": {
        "id": "833ab690"
      },
      "outputs": [],
      "source": [
        "# Inicializa√ß√µes\n",
        "import openai\n",
        "import pinecone\n",
        "from pymongo import MongoClient\n",
        "import uuid\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)\n",
        "\n",
        "# Pinecone\n",
        "if pinecone_index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(pinecone_index_name, dimension=1536)\n",
        "index = pinecone.Index(pinecone_index_name)\n",
        "\n",
        "# MongoDB\n",
        "mongo = MongoClient(mongodb_uri)\n",
        "collection = mongo[db_name][collection_name]\n",
        "\n",
        "def gerar_embedding(texto):\n",
        "    response = openai.Embedding.create(input=[texto], model=\"text-embedding-ada-002\")\n",
        "    return response[\"data\"][0][\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df8fed7",
      "metadata": {
        "id": "5df8fed7"
      },
      "outputs": [],
      "source": [
        "# Inserir base de conhecimento\n",
        "faq_data = [\n",
        "    {\"pergunta\": \"Como redefinir minha senha?\", \"resposta\": \"Acesse configura√ß√µes e clique em 'Redefinir Senha'.\"},\n",
        "    {\"pergunta\": \"Qual √© o hor√°rio de atendimento?\", \"resposta\": \"Das 8h √†s 18h, de segunda a sexta.\"},\n",
        "    {\"pergunta\": \"Onde posso baixar minha fatura?\", \"resposta\": \"Na √°rea do cliente, se√ß√£o 'Faturas'.\"}\n",
        "]\n",
        "\n",
        "for item in faq_data:\n",
        "    item_id = str(uuid.uuid4())\n",
        "    vetor = gerar_embedding(item[\"pergunta\"])\n",
        "    item[\"_id\"] = item_id\n",
        "    collection.insert_one(item)\n",
        "    index.upsert([(item_id, vetor)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5529e4e3",
      "metadata": {
        "id": "5529e4e3"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o de busca com recupera√ß√£o sem√¢ntica\n",
        "def buscar_contexto(pergunta, top_k=1):\n",
        "    embedding = gerar_embedding(pergunta)\n",
        "    results = index.query(vector=embedding, top_k=top_k)\n",
        "    contextos = []\n",
        "    for match in results[\"matches\"]:\n",
        "        doc = collection.find_one({\"_id\": match[\"id\"]})\n",
        "        if doc:\n",
        "            contextos.append(doc[\"resposta\"])\n",
        "    return \"\\n\".join(contextos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0e2e3f",
      "metadata": {
        "id": "5c0e2e3f"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o de resposta com contexto RAG\n",
        "def responder(pergunta):\n",
        "    contexto = buscar_contexto(pergunta)\n",
        "    prompt = f\"\"\"\n",
        "Contexto:\n",
        "{contexto}\n",
        "\n",
        "Pergunta:\n",
        "{pergunta}\n",
        "\n",
        "Responda com base apenas no contexto acima.\n",
        "\"\"\"\n",
        "    resposta = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resposta[\"choices\"][0][\"message\"][\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a95133",
      "metadata": {
        "id": "79a95133"
      },
      "outputs": [],
      "source": [
        "# Teste interativo\n",
        "while True:\n",
        "    pergunta = input(\"Voc√™: \")\n",
        "    if pergunta.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
        "        break\n",
        "    resposta = responder(pergunta)\n",
        "    print(\"Bot:\", resposta)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üöÄ Como utilizar o notebook RAG com Pinecone + MongoDB + OpenAI\n",
        "\n",
        "### üîß Pr√©-requisitos\n",
        "\n",
        "Antes de rodar o notebook, voc√™ precisa:\n",
        "\n",
        "1. **Criar contas e obter chaves:**\n",
        "\n",
        "   * [OpenAI](https://platform.openai.com/account/api-keys): gere sua `openai_api_key`\n",
        "   * [Pinecone](https://app.pinecone.io): gere sua `pinecone_api_key` e anote o `environment` (ex: `us-west1-gcp`)\n",
        "\n",
        "2. **Instalar o MongoDB:**\n",
        "\n",
        "   * Localmente ou via [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Etapas no notebook\n",
        "\n",
        "#### ‚úÖ 1. Instalar depend√™ncias\n",
        "\n",
        "Executa `pip install` para instalar:\n",
        "\n",
        "* `openai`\n",
        "* `pinecone-client`\n",
        "* `pymongo`\n",
        "\n",
        "#### ‚úÖ 2. Definir vari√°veis de configura√ß√£o\n",
        "\n",
        "Voc√™ deve substituir:\n",
        "\n",
        "```python\n",
        "openai_api_key = \"SUA_OPENAI_API_KEY\"\n",
        "pinecone_api_key = \"SUA_PINECONE_API_KEY\"\n",
        "pinecone_env = \"SUA_PINECONE_ENV\"\n",
        "mongodb_uri = \"mongodb://localhost:27017\"\n",
        "```\n",
        "\n",
        "#### ‚úÖ 3. Inicializa√ß√µes\n",
        "\n",
        "* Conecta √† API do OpenAI\n",
        "* Conecta ao Pinecone (cria √≠ndice se n√£o existir)\n",
        "* Conecta ao MongoDB (banco + cole√ß√£o para persist√™ncia textual)\n",
        "\n",
        "#### ‚úÖ 4. Inserir documentos de base\n",
        "\n",
        "Voc√™ pode inserir perguntas e respostas como esta:\n",
        "\n",
        "```python\n",
        "{ \"pergunta\": \"Como redefinir minha senha?\", \"resposta\": \"Acesse configura√ß√µes e clique em 'Redefinir Senha'.\" }\n",
        "```\n",
        "\n",
        "Cada pergunta √© transformada em um vetor sem√¢ntico via `text-embedding-ada-002` e enviada ao Pinecone + MongoDB.\n",
        "\n",
        "#### ‚úÖ 5. Buscar contexto\n",
        "\n",
        "A fun√ß√£o `buscar_contexto(pergunta)` realiza:\n",
        "\n",
        "* Convers√£o da pergunta em vetor\n",
        "* Consulta sem√¢ntica no Pinecone\n",
        "* Recupera√ß√£o do texto correspondente no MongoDB\n",
        "\n",
        "#### ‚úÖ 6. Gerar resposta com GPT\n",
        "\n",
        "A fun√ß√£o `responder(pergunta)` monta um prompt com:\n",
        "\n",
        "* Contexto recuperado\n",
        "* Pergunta original\n",
        "\n",
        "E envia ao modelo `gpt-3.5-turbo` da OpenAI.\n",
        "\n",
        "#### ‚úÖ 7. Intera√ß√£o final\n",
        "\n",
        "Um loop `input()` permite que voc√™ converse com o sistema e ele responda com base no conhecimento armazenado.\n",
        "\n",
        "---\n",
        "\n",
        "### üì¶ Dica: Atualizar a base de conhecimento\n",
        "\n",
        "Voc√™ pode adicionar dinamicamente novos documentos no MongoDB e no Pinecone executando novamente a c√©lula de inser√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "### üîê Seguran√ßa\n",
        "\n",
        "* Nunca exponha suas chaves diretamente em c√≥digo p√∫blico.\n",
        "* Para projetos reais, use vari√°veis de ambiente (`os.getenv`) ou arquivos `.env`.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "wHpg6dumo7Ux"
      },
      "id": "wHpg6dumo7Ux"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGH5Us4vo4Iu"
      },
      "id": "YGH5Us4vo4Iu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}