{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database"
      ],
      "metadata": {
        "id": "EHTLXkKOD3bj"
      },
      "id": "EHTLXkKOD3bj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Um Vector Database (ou banco de dados vetorial) √© um tipo de banco de dados especializado no armazenamento, indexa√ß√£o e busca eficiente de vetores de alta dimens√£o ‚Äî representa√ß√µes num√©ricas densas, geralmente extra√≠das de dados como textos, imagens, v√≠deos ou √°udio.\n",
        "\n",
        "Esses vetores s√£o a base de aplica√ß√µes de IA modernas, como:\n",
        "\n",
        "Busca sem√¢ntica (semantic search)\n",
        "\n",
        "Recupera√ß√£o aumentada por gera√ß√£o (RAG)\n",
        "\n",
        "Recomenda√ß√£o de conte√∫do\n",
        "\n",
        "Detec√ß√£o de similaridade\n",
        "\n",
        "üß† Por que vetores?\n",
        "Modelos de machine learning (como BERT, CLIP, OpenAI embeddings etc.) convertem entradas complexas (como textos) em vetores num√©ricos. Cada vetor representa o \"significado\" daquele dado em um espa√ßo matem√°tico. Com isso, √© poss√≠vel medir semelhan√ßa sem√¢ntica usando m√©tricas como:\n",
        "\n",
        "Dist√¢ncia Euclidiana\n",
        "\n",
        "Cosseno\n",
        "\n",
        "Inner product\n",
        "\n",
        "üå≤ Pinecone ‚Äì O que √©?\n",
        "\n",
        "Pinecone √© uma Vector Database as a Service, gerenciada, escal√°vel e de alta performance. Ela permite que voc√™:\n",
        "\n",
        "Armazene bilh√µes de vetores\n",
        "\n",
        "Fa√ßa buscas vetoriais r√°pidas\n",
        "\n",
        "Integre facilmente com LLMs (ex: OpenAI, Cohere)\n",
        "\n",
        "Use com frameworks como LangChain, LlamaIndex, Haystack\n",
        "\n",
        "üõ†Ô∏è Como funciona a arquitetura b√°sica?\n",
        "Cria√ß√£o de vetores: Um modelo de IA transforma dados (como textos) em vetores.\n",
        "\n",
        "Indexa√ß√£o: Esses vetores s√£o armazenados em Pinecone.\n",
        "\n",
        "Consulta: Voc√™ envia um vetor de consulta, e Pinecone retorna os vetores mais semelhantes.\n",
        "\n",
        "Integra√ß√£o com contexto: Em sistemas RAG, os resultados recuperados podem ser usados como contexto para LLMs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sTaqRFjNDswf"
      },
      "id": "sTaqRFjNDswf"
    },
    {
      "cell_type": "markdown",
      "id": "5ece3236",
      "metadata": {
        "id": "5ece3236"
      },
      "source": [
        "# üîç RAG com Pinecone + MongoDB + OpenAI\n",
        "\n",
        "Este notebook demonstra como construir um sistema de **Pergunta e Resposta com Busca Sem√¢ntica** (RAG - Retrieval-Augmented Generation), integrando:\n",
        "- Vetores sem√¢nticos com OpenAI\n",
        "- Armazenamento vetorial com Pinecone\n",
        "- Persist√™ncia dos documentos em MongoDB\n",
        "- Gera√ß√£o de resposta com contexto usando ChatGPT (GPT-3.5-turbo)\n",
        "\n",
        "Ideal para casos de uso como:\n",
        "- FAQ inteligentes\n",
        "- Chatbots com mem√≥ria contextual\n",
        "- Sistemas de suporte baseados em conhecimento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obter suas chaves de API do **Pinecone** e **OpenAI**, siga os passos abaixo:\n",
        "\n",
        "---\n",
        "\n",
        "### üîë **1. Como obter a API Key do Pinecone**\n",
        "\n",
        "1. Acesse: [https://www.pinecone.io](https://www.pinecone.io)\n",
        "2. Clique em **‚ÄúStart for free‚Äù** e crie uma conta (ou fa√ßa login).\n",
        "3. No Dashboard:\n",
        "\n",
        "   * V√° para **API Keys** (menu lateral esquerdo).\n",
        "   * Copie a **API Key** (ex: `a1b2c3d4...`) e o **Environment** (ex: `gcp-starter`, `us-west1-gcp`).\n",
        "\n",
        "‚ö†Ô∏è Guarde essas informa√ß√µes, voc√™ usar√° assim:\n",
        "\n",
        "```python\n",
        "pinecone_api_key = \"SUA_PINECONE_API_KEY\"\n",
        "pinecone_env = \"us-west1-gcp\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîê **2. Como obter a OpenAI API Key**\n",
        "\n",
        "1. Acesse: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n",
        "2. Fa√ßa login com sua conta da OpenAI.\n",
        "3. Clique em **‚ÄúCreate new secret key‚Äù**.\n",
        "4. Copie e salve a chave (voc√™ s√≥ ver√° uma vez!).\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "```python\n",
        "openai_api_key = \"sk-...\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üí° Dica de seguran√ßa:\n",
        "\n",
        "* Nunca compartilhe suas chaves publicamente.\n",
        "* Use vari√°veis de ambiente (como `os.getenv`) ou arquivos `.env` para maior seguran√ßa em produ√ß√£o.\n",
        "\n",
        "Se quiser, posso mostrar como armazenar essas chaves com seguran√ßa em um projeto Colab ou Python local. Deseja isso tamb√©m?\n"
      ],
      "metadata": {
        "id": "8sw32BTcEczT"
      },
      "id": "8sw32BTcEczT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48459f6",
      "metadata": {
        "id": "e48459f6"
      },
      "outputs": [],
      "source": [
        "# Instalar depend√™ncias\n",
        "!pip install openai pinecone-client pymongo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c807df7a",
      "metadata": {
        "id": "c807df7a"
      },
      "outputs": [],
      "source": [
        "# Configura√ß√µes (edite com suas chaves)\n",
        "openai_api_key = \"SUA_OPENAI_API_KEY\"\n",
        "pinecone_api_key = \"SUA_PINECONE_API_KEY\"\n",
        "pinecone_env = \"us-west1-gcp\"\n",
        "pinecone_index_name = \"rag-index\"\n",
        "\n",
        "mongodb_uri = \"mongodb://localhost:27017\"\n",
        "db_name = \"ragdb\"\n",
        "collection_name = \"faq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833ab690",
      "metadata": {
        "id": "833ab690"
      },
      "outputs": [],
      "source": [
        "# Inicializa√ß√µes\n",
        "import openai\n",
        "import pinecone\n",
        "from pymongo import MongoClient\n",
        "import uuid\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)\n",
        "\n",
        "# Pinecone\n",
        "if pinecone_index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(pinecone_index_name, dimension=1536)\n",
        "index = pinecone.Index(pinecone_index_name)\n",
        "\n",
        "# MongoDB\n",
        "mongo = MongoClient(mongodb_uri)\n",
        "collection = mongo[db_name][collection_name]\n",
        "\n",
        "def gerar_embedding(texto):\n",
        "    response = openai.Embedding.create(input=[texto], model=\"text-embedding-ada-002\")\n",
        "    return response[\"data\"][0][\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df8fed7",
      "metadata": {
        "id": "5df8fed7"
      },
      "outputs": [],
      "source": [
        "# Inserir base de conhecimento\n",
        "faq_data = [\n",
        "    {\"pergunta\": \"Como redefinir minha senha?\", \"resposta\": \"Acesse configura√ß√µes e clique em 'Redefinir Senha'.\"},\n",
        "    {\"pergunta\": \"Qual √© o hor√°rio de atendimento?\", \"resposta\": \"Das 8h √†s 18h, de segunda a sexta.\"},\n",
        "    {\"pergunta\": \"Onde posso baixar minha fatura?\", \"resposta\": \"Na √°rea do cliente, se√ß√£o 'Faturas'.\"}\n",
        "]\n",
        "\n",
        "for item in faq_data:\n",
        "    item_id = str(uuid.uuid4())\n",
        "    vetor = gerar_embedding(item[\"pergunta\"])\n",
        "    item[\"_id\"] = item_id\n",
        "    collection.insert_one(item)\n",
        "    index.upsert([(item_id, vetor)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5529e4e3",
      "metadata": {
        "id": "5529e4e3"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o de busca com recupera√ß√£o sem√¢ntica\n",
        "def buscar_contexto(pergunta, top_k=1):\n",
        "    embedding = gerar_embedding(pergunta)\n",
        "    results = index.query(vector=embedding, top_k=top_k)\n",
        "    contextos = []\n",
        "    for match in results[\"matches\"]:\n",
        "        doc = collection.find_one({\"_id\": match[\"id\"]})\n",
        "        if doc:\n",
        "            contextos.append(doc[\"resposta\"])\n",
        "    return \"\\n\".join(contextos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0e2e3f",
      "metadata": {
        "id": "5c0e2e3f"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o de resposta com contexto RAG\n",
        "def responder(pergunta):\n",
        "    contexto = buscar_contexto(pergunta)\n",
        "    prompt = f\"\"\"\n",
        "Contexto:\n",
        "{contexto}\n",
        "\n",
        "Pergunta:\n",
        "{pergunta}\n",
        "\n",
        "Responda com base apenas no contexto acima.\n",
        "\"\"\"\n",
        "    resposta = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return resposta[\"choices\"][0][\"message\"][\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a95133",
      "metadata": {
        "id": "79a95133"
      },
      "outputs": [],
      "source": [
        "# Teste interativo\n",
        "while True:\n",
        "    pergunta = input(\"Voc√™: \")\n",
        "    if pergunta.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
        "        break\n",
        "    resposta = responder(pergunta)\n",
        "    print(\"Bot:\", resposta)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}